{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping demo\n",
    "## Amazon Product Reviews\n",
    "### Changes may be required due to tag updates\n",
    "\n",
    "(c) Nuno Ant√≥nio 2020-2025 - Rev. 1.20 (2025-04-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and do the initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random user-agent string\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Firefox options (configurations)\n",
    "options = Options()\n",
    "\n",
    "# Add options to fake agent\n",
    "options.set_preference(\"general.useragent.override\", user_agent)\n",
    "\n",
    "# Add this argument to Options to hide Firefox (make it not visible)\n",
    "# options.add_argument('--headless') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of the hotels to read the content\n",
    "productsToScrap = pd.read_excel(\"LaptopsToScrap.xlsx\", sheet_name=\"Sheet1\", index_col=\"ID\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  URL\n",
      "ID                                                                                                   \n",
      "Lenovo Flex 5 14\" 2-in-1 Laptop, 14.0\" FHD (192...  https://www.amazon.com/Lenovo-Processor-Graphi...\n",
      "Acer Chromebook Spin 311 Convertible Laptop, In...  https://www.amazon.com/Acer-Chromebook-Convert...\n"
     ]
    }
   ],
   "source": [
    "print(productsToScrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe for the resuls\n",
    "productReviews = pd.DataFrame({'productID': pd.Series([], dtype='string'),\n",
    "                             'user': pd.Series([], dtype='string'),\n",
    "                             'verified': pd.Series([], dtype='string'),\n",
    "                             'rating': pd.Series([], dtype='float'),\n",
    "                             'reviewDate': pd.Series([], dtype='string'),\n",
    "                             'reviewCountry': pd.Series([], dtype='string'),\n",
    "                             'text': pd.Series([], dtype='string'),\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to use in the Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open page and read HTML\n",
    "def open_page_read_html(url, browser):\n",
    "    browser.get(url)\n",
    "    time.sleep(random.uniform(3, 5))  # Wait for page to load\n",
    "    return BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each page\n",
    "def processPage(soup, productID, extractedDF):\n",
    "    reviews = soup.find_all(\"li\", {\"data-hook\": \"review\"})\n",
    "\n",
    "    for review in reviews:\n",
    "        # Get Rating\n",
    "        reviewRating = float(review.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip())\n",
    "\n",
    "        # Get User\n",
    "        user = review.select(\"span[class*=a-profile-name]\")[0].string\n",
    "\n",
    "        # Get Verified or not\n",
    "        verified_span = review.find('span', {'data-hook': 'avp-badge'})\n",
    "        verified = verified_span.string if verified_span else \"Not verified\"\n",
    "\n",
    "        # Get review text\n",
    "        reviewText = review.find('span', {'data-hook': 'review-body'}).text.strip()\n",
    "\n",
    "        # Get review Date\n",
    "        reviewDateTemp = review.find('span', {'data-hook': 'review-date'}).string\n",
    "        reviewDate = reviewDateTemp.strip().split(\"on\")[1]\n",
    "\n",
    "        # Get review Country\n",
    "        reviewCountry = reviewDateTemp.replace('Reviewed in', '').strip().split(\"on\")[0]\n",
    "\n",
    "        # Update extracted reviews dataframe\n",
    "        tDF = pd.DataFrame({\n",
    "            'productID': [productID],\n",
    "            'user': [user],\n",
    "            'verified': [verified],\n",
    "            'rating': [reviewRating],\n",
    "            'reviewDate': [reviewDate],\n",
    "            'reviewCountry': [reviewCountry],\n",
    "            'text': [reviewText],\n",
    "        })\n",
    "        extractedDF = pd.concat([extractedDF, tDF], ignore_index=True)\n",
    "\n",
    "    # Return the resulting dataframe\n",
    "    return extractedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe for the resuls\n",
    "productReviews = pd.DataFrame({'productID': pd.Series([], dtype='string'),\n",
    "                             'user': pd.Series([], dtype='string'),\n",
    "                             'verified': pd.Series([], dtype='string'),\n",
    "                             'rating': pd.Series([], dtype='float'),\n",
    "                             'reviewDate': pd.Series([], dtype='string'),\n",
    "                             'reviewCountry': pd.Series([], dtype='string'),\n",
    "                             'text': pd.Series([], dtype='string'),\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening browser\n"
     ]
    }
   ],
   "source": [
    "# Open browser and navigate to login page\n",
    "print(\"Opening browser\")\n",
    "browser = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Amazon website\n",
    "temp = open_page_read_html(\"http://www.amazon.com\", browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DO NOT RUN THE FOLLOWING CODE BEFORE SOLVING THE CAPTCHA AND SIGN IN THE OPENED BROWSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because this is a demo, let's define the maximum number of reviews to obtain per product\n",
    "reviewsToGet = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing product Lenovo Flex 5 14\" 2-in-1 Laptop, 14.0\" FHD (1920 x 1080) Touch Display, AMD Ryzen 5 4500U Processor, 16GB DDR4, 256GB SSD, AMD Radeon Graphics, Digital Pen Included, Win 10, 81X20005US, Graphite Grey \n",
      "Extracted 20 / 20\n",
      "Processing product Acer Chromebook Spin 311 Convertible Laptop, Intel Celeron N4020, 11.6\" HD Touch, 4GB LPDDR4, 32GB eMMC, Gigabit Wi-Fi 5, Bluetooth 5.0, Google Chrome, CP311-2H-C679 \n",
      "Extracted 20 / 20\n",
      "Closing browser\n",
      "Browser closed\n"
     ]
    }
   ],
   "source": [
    "# Loop for all product\n",
    "for index, row in productsToScrap.iterrows():\n",
    "    print(f\"Processing product {index}\")\n",
    "    urlToUse = row['URL']\n",
    "    productReviewsCount = 0  # Initialize review count for the current product\n",
    "    pageNumber = 1\n",
    "\n",
    "    while productReviewsCount < reviewsToGet:\n",
    "        # Open and read the web page content\n",
    "        soup = open_page_read_html(urlToUse, browser)\n",
    "\n",
    "        # Process web page\n",
    "        productReviews = processPage(soup, index, productReviews)\n",
    "        \n",
    "        # Calculate the extracted reviews in current loop\n",
    "        extracted_reviews_count = len(productReviews[productReviews['productID'] == str(index)])\n",
    "        \n",
    "        # Number of reviews from the current product\n",
    "        productReviewsCount = extracted_reviews_count\n",
    "        \n",
    "        # Click the next page button \n",
    "        try:\n",
    "            next_button = WebDriverWait(browser, random.uniform(5,10)).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"li.a-last a\"))\n",
    "            )\n",
    "            next_button.click()\n",
    "            \n",
    "            # Wait for page to load after click\n",
    "            WebDriverWait(browser, random.uniform(5,10)).until(\n",
    "                EC.staleness_of(next_button)\n",
    "            )\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"No more pages available\")\n",
    "            break\n",
    "\n",
    "        print(f\"Extracted {productReviewsCount} / {reviewsToGet}\")\n",
    "\n",
    "\n",
    "# Close browser\n",
    "print(\"Closing browser\")\n",
    "browser.quit()    \n",
    "print(\"Browser closed\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the extracted reviews data frame to an Excel file\n",
    "productReviews.to_excel(\"ExtractedReviews_Amazon.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
